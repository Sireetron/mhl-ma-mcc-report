{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "from connector import tableau_db_params\n",
    "from datetime import datetime, timedelta\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_queries = os.getenv('REPORT_SERVICE')\n",
    "\n",
    "# Load environment variables from the .env file\n",
    "\n",
    "month = datetime.now().month -1\n",
    "year = datetime.now().year\n",
    "api_params = {'month': '09', 'year': '2023'}\n",
    "\n",
    "def get_first_and_last_day_of_month(year, month):\n",
    "    first_day = datetime(year, month, 1)\n",
    "    last_day = datetime(year, month + 1, 1) - timedelta(days=1)\n",
    "    \n",
    "    return first_day.strftime('%Y-%m-%d'), last_day.strftime('%Y-%m-%d')\n",
    "\n",
    "# Example for September 2023\n",
    "first_day, last_day = get_first_and_last_day_of_month(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pg_conn = psycopg2.connect(**tableau_db_params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# line chart (╯ ͡❛ ͜ʖ ͡❛)╯┻━┻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import numpy as np\n",
    "import requests\n",
    "from urllib.parse import urlparse, parse_qs\n",
    "\n",
    "url = os.getenv('REPORT_SERVICE')+f\"tableau/Disk_lineplot_Usage?month={month}&year={year}\"  #\"http://localhost:1234/report-service/api/v1/tableau/Disk_lineplot_Usage?month=11&year=2023\"\n",
    "\n",
    "# แยกพารามิเตอร์จาก URL\n",
    "parsed_url = urlparse(url)\n",
    "\n",
    "# ดึงค่าเดือนจากพารามิเตอร์\n",
    "is_month = int(parse_qs(parsed_url.query).get('month', [])[0])\n",
    "\n",
    "# Add Bearer token to the request headers\n",
    "headers = {\n",
    "    'Authorization': 'Bearer POPPOPNIX',  # Replace '1234' with your actual token\n",
    "}\n",
    "\n",
    "# Fetch JSON data from the URL with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    json_data = response.json()\n",
    "    \n",
    "    # Extract the 'data' key from the JSON data\n",
    "    data_list1 = json_data.get('total_runs', {}).get('data', [])\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    disk_df = pd.DataFrame(data_list1)\n",
    "    \n",
    "    # Now you can use the DataFrame 'disk_df' for further analysis or visualization\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "def bytes_to_gb(bytes):\n",
    "    gb = bytes / (1024 ** 3)\n",
    "    return gb\n",
    "\n",
    "disk_df['total_space_gb'] = disk_df['total_space_bytes'].map(bytes_to_gb)\n",
    "disk_df['used_space_gb'] = disk_df['used_space_bytes'].map(bytes_to_gb)\n",
    "\n",
    "disk_df['record_timestamp'] = pd.to_datetime(disk_df['record_timestamp'])\n",
    "disk_df = disk_df.sort_values('record_timestamp')\n",
    "\n",
    "# Check if the month is October\n",
    "is_october = disk_df['record_timestamp'].dt.month == is_month\n",
    "\n",
    "# Create the plot\n",
    "fig, ax1 = plt.subplots(figsize=(10, 3))\n",
    "\n",
    "# Plot the total space on the first axis\n",
    "ax1.plot(disk_df['record_timestamp'], disk_df['total_space_gb'], 'r', label='จำนวนพื้นที่ทั้งหมด (GB)')\n",
    "\n",
    "# Plot the used space on the first axis\n",
    "ax1.plot(disk_df['record_timestamp'], disk_df['used_space_gb'], 'b--', label='จำนวนการใช้พื้นที่ (GB)')\n",
    "\n",
    "ax1.set_xlabel('วันที่')\n",
    "ax1.set_ylabel('การใช้ข้อมูล (GB)')\n",
    "\n",
    "# Create a secondary axis for the percentage\n",
    "ax2 = ax1.twinx()\n",
    "plt.rcParams['font.family'] = 'Tahoma'\n",
    "\n",
    "# Calculate the used space percentage\n",
    "used_space_percentage = (disk_df['used_space_bytes'] / disk_df['total_space_bytes']) * 100\n",
    "\n",
    "# Plot the used space percentage on the secondary axis\n",
    "if is_october.any():\n",
    "    ax2.plot(disk_df[is_october]['record_timestamp'], used_space_percentage[is_october], 'b')\n",
    "if (~is_october).any():\n",
    "    ax2.plot(disk_df[~is_october]['record_timestamp'], used_space_percentage[~is_october], 'b--')\n",
    "\n",
    "ax2.set_ylabel('การใช้พื้นที่เป็นจำนวนเปอร์เซ็น')\n",
    "\n",
    "# Combine legends from both axes\n",
    "lines_1, labels_1 = ax1.get_legend_handles_labels()\n",
    "lines_2, labels_2 = ax2.get_legend_handles_labels()\n",
    "lines = lines_1 + lines_2\n",
    "labels = labels_1 + labels_2\n",
    "ax1.legend(lines, labels, loc='upper left')\n",
    "\n",
    "ax1.set_axisbelow(True)\n",
    "ax1.grid(linestyle='--', linewidth=0.5)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performace bar (╯ ͡❛ ͜ʖ ͡❛)╯┻━┻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# Specify the URL to fetch JSON data\n",
    "url = os.getenv('REPORT_SERVICE')+f\"tableau/Get_Performace_Dashboard?month={month}&year={year}\" #\"http://localhost:1234/report-service/api/v1/tableau/Get_Performace_Dashboard?month=12&year=2023\"\n",
    "\n",
    "# Add Bearer token to the request headers\n",
    "headers = {\n",
    "    'Authorization': 'Bearer POPPOPNIX',  # Replace '1234' with your actual token\n",
    "}\n",
    "\n",
    "# Fetch JSON data from the URL with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    json_data = response.json()\n",
    "    \n",
    "    # Extract the 'data' key from the JSON data\n",
    "    data_list1 = json_data.get('total_runs', {}).get('data', [])\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data_list1)\n",
    "\n",
    "# Assuming you have a DataFrame called 'data' with the provided data\n",
    "\n",
    "# Calculate the IQR (Interquartile Range) for elapsed_time_sec\n",
    "Q1 = df['elapsed_time_sec'].quantile(0.25)\n",
    "Q3 = df['elapsed_time_sec'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "# Define the lower and upper bounds for outliers\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "# Filter the data to remove outliers\n",
    "filtered_data = df\n",
    "plt.rcParams['font.family'] = 'Tahoma'\n",
    "\n",
    "# Sort the View Names by count of data points (records)\n",
    "sorted_view_names = filtered_data['name'].value_counts().head(10).index\n",
    "\n",
    "# Create a boxplot for each View Name and stack them together\n",
    "fig, ax = plt.subplots(figsize=(15, 8))\n",
    "boxplot_data = [filtered_data[filtered_data['name'] == view_name]['elapsed_time_sec'] for view_name in sorted_view_names]\n",
    "\n",
    "# Set the boxplot colors\n",
    "default_color = '#7ED957'\n",
    "colors = [default_color if view_name != 'รายงานวิเคราะห์ข้อมูลท่อรั่วราย DMA' else '#FF3131' for view_name in sorted_view_names]\n",
    "\n",
    "bp = ax.boxplot(boxplot_data, vert=False, labels=sorted_view_names, showfliers=False, patch_artist=True)\n",
    "\n",
    "# Loop through the boxplots to set the box colors\n",
    "for box, color in zip(bp['boxes'], colors):\n",
    "    box.set(facecolor=color, color=color)\n",
    "\n",
    "ax.set_xlabel('เวลาโหลด (วินาที)')\n",
    "ax.set_ylabel('ชื่อ View')\n",
    "\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# Create custom legend entries\n",
    "legend_elements = [mlines.Line2D([], [], color=default_color, label='< 10 วินาที'),\n",
    "                   mlines.Line2D([], [], color='#FF3131', label='> 10 วินาที')]\n",
    "\n",
    "# Add legend\n",
    "ax.legend(handles=legend_elements)\n",
    "\n",
    "# ax.set_title('Load time of top 10 most view dashboards')\n",
    "ax.grid()\n",
    "ax.get_axisbelow()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracts Dot (╯ ͡❛ ͜ʖ ͡❛)╯┻━┻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_query = '''\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    SELECT\n",
    "        bj.created_at AS created_at_local,\n",
    "        bj.id AS ID,\n",
    "        v.name AS Extract,\n",
    "        bj.completed_at AS completed_at_local_nonull,\n",
    "        bj.backgrounder_id AS Backgrounder_Id,\n",
    "        bj.completed_at AS completed_at_local,\n",
    "        bj.job_name AS Job_Name,\n",
    "        aj.notes AS Notes,\n",
    "        bj.priority AS Priority,\n",
    "        bj.processed_on_worker AS Processed_On_Worker,\n",
    "        bj.started_at AS started_at_local,\n",
    "        CASE\n",
    "            WHEN bj.finish_code = 0 THEN 'success'\n",
    "            WHEN bj.finish_code = 1 THEN 'failure'\n",
    "            WHEN bj.finish_code = 2 THEN 'cancelled'\n",
    "            ELSE 'unknown'\n",
    "        END AS status_job,\n",
    "        bj.title AS Title,\n",
    "        bj.job_name AS exetract_task,\n",
    "        s.name AS Site,\n",
    "        bj.finish_code as finish_code,\n",
    "        bj.progress AS progress\n",
    "    FROM\n",
    "        background_jobs bj\n",
    "    LEFT JOIN sites s ON bj.site_id = s.id\n",
    "    LEFT JOIN views v ON s.id = v.site_id\n",
    "    LEFT JOIN async_jobs aj ON s.id = aj.site_id\n",
    "    WHERE \n",
    "        Job_Name = 'Refresh Extracts' AND\n",
    "        EXTRACT(MONTH FROM bj.created_at) = 11 AND \n",
    "        EXTRACT(YEAR FROM bj.created_at) = 2023\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "df = pd.read_sql_query(st_query, pg_conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Define the path to your JSON file\n",
    "json_file_path = r'C:\\work_on_maholan\\mhl-de-ma-report\\json_file\\Extracts_dot_m11.json'\n",
    "\n",
    "# Read JSON file into DataFrame\n",
    "df = pd.read_json(json_file_path)\n",
    "\n",
    "# Convert the 'Started At' column to a datetime type\n",
    "df['Started At'] = pd.to_datetime(df['Started At'])\n",
    "\n",
    "# Filter the DataFrame to include \"Error\" and \"Success\" status\n",
    "error_df = df[df['Status of Job'] == 'Error']\n",
    "success_df = df[df['Status of Job'] == 'Success']\n",
    "\n",
    "# Create the scatter plot for \"Error\" status\n",
    "plt.figure(figsize=(12, 6))\n",
    "error_color = 'red'  # Color for \"Error\" data points\n",
    "plt.scatter(error_df['Started At'], error_df['Extract'], c=error_color, label='มีการทำงานซ้ำ', alpha=0.5)\n",
    "\n",
    "# Create the scatter plot for \"Success\" status\n",
    "success_color = '#7ED957'  # Color for \"Success\" data points\n",
    "plt.scatter(success_df['Started At'], success_df['Extract'], c=success_color, label='สำเร็จ', alpha=0.5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('วันที่')\n",
    "plt.ylabel('หน้า dashbord')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Set the x-axis format to show ticks at 12-hour intervals\n",
    "plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=24))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Define the custom legend using Line2D\n",
    "custom_legend = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF7D7D', markersize=10, label='ไม่มีการทำงานซ้ำ'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF0000', markersize=10, label='มีการทำงานซ้ำ'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#7ED957', markersize=10, label='สำเร็จ')\n",
    "]\n",
    "\n",
    "# Place the legend outside the plot\n",
    "plt.legend(handles=custom_legend, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of the legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Define the path to your JSON file\n",
    "json_file_path = r'C:\\work_on_maholan\\mhl-de-ma-report\\json_file\\Extracts_dot_m10.json'\n",
    "\n",
    "# Read JSON file into DataFrame\n",
    "df = pd.read_json(json_file_path)\n",
    "\n",
    "# Convert the 'Started At' column to a datetime type\n",
    "df['Started At'] = pd.to_datetime(df['started_at_local'])\n",
    "\n",
    "# Filter the DataFrame to include \"Error\" and \"Success\" status\n",
    "error_df = df[df['Status of Job'] == 'Error']\n",
    "success_df = df[df['Status of Job'] == 'Success']\n",
    "\n",
    "# Create the scatter plot for \"Error\" status\n",
    "plt.figure(figsize=(12, 6))\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Assuming df is your DataFrame containing the necessary columns\n",
    "\n",
    "# Convert the 'created_at_local' column to a datetime type\n",
    "df['created_at_local'] = pd.to_datetime(df['created_at_local'])\n",
    "\n",
    "# Filter the DataFrame to include \"Error\" and \"Success\" status\n",
    "error_df = df[df['status_job'] == 'failure']  # Assuming 'failure' corresponds to 'Error'\n",
    "success_df = df[df['status_job'] == 'success']  # Assuming 'success' corresponds to 'Success'\n",
    "\n",
    "# Create the scatter plot for \"Error\" status\n",
    "plt.figure(figsize=(12, 6))\n",
    "error_color = 'red'  # Color for \"Error\" data points\n",
    "plt.scatter(error_df['created_at_local'], error_df['title'], c=error_color, label='มีการทำงานซ้ำ', alpha=0.5)\n",
    "\n",
    "# Create the scatter plot for \"Success\" status\n",
    "success_color = '#7ED957'  # Color for \"Success\" data points\n",
    "plt.scatter(success_df['created_at_local'], success_df['title'], c=success_color, label='สำเร็จ', alpha=0.5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('วันที่')\n",
    "plt.ylabel('หน้า dashboard')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Set the x-axis format to show ticks at 12-hour intervals\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator())  # Adjusted to show ticks at daily intervals\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Define the custom legend using Line2D\n",
    "custom_legend = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF0000', markersize=10, label='มีการทำงานซ้ำ'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#7ED957', markersize=10, label='สำเร็จ')\n",
    "]\n",
    "\n",
    "# Place the legend outside the plot\n",
    "plt.legend(handles=custom_legend, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of the legend\n",
    "plt.show()\n",
    "\n",
    "error_color = 'red'  # Color for \"Error\" data points\n",
    "plt.scatter(error_df['Started At'], error_df['Extract'], c=error_color, label='มีการทำงานซ้ำ', alpha=0.5)\n",
    "\n",
    "# Create the scatter plot for \"Success\" status\n",
    "success_color = '#7ED957'  # Color for \"Success\" data points\n",
    "plt.scatter(success_df['Started At'], success_df['Extract'], c=success_color, label='สำเร็จ', alpha=0.5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('วันที่')\n",
    "plt.ylabel('หน้า dashbord')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "# Set the x-axis format to show ticks at 12-hour intervals\n",
    "plt.gca().xaxis.set_major_locator(mdates.HourLocator(interval=24))\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M'))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Define the custom legend using Line2D\n",
    "custom_legend = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF7D7D', markersize=10, label='ไม่มีการทำงานซ้ำ'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF0000', markersize=10, label='มีการทำงานซ้ำ'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#7ED957', markersize=10, label='สำเร็จ')\n",
    "]\n",
    "\n",
    "# Place the legend outside the plot\n",
    "plt.legend(handles=custom_legend, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of the legend\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spec_use_donut (╯ ͡❛ ͜ʖ ͡❛)╯┻━┻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# Specify the URL to fetch JSON data\n",
    "url = os.getenv('REPORT_SERVICE')+\"tableau/Top5_Space_Usage_By_Workbook\" #\"http://localhost:1234/report-service/api/v1/tableau/Top5_Space_Usage_By_Workbook\"\n",
    "\n",
    "# Add Bearer token to the request headers\n",
    "headers = {\n",
    "    'Authorization': 'Bearer POPPOPNIX',  # Replace '1234' with your actual token\n",
    "}\n",
    "\n",
    "# Fetch JSON data from the URL with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    json_data = response.json()\n",
    "    \n",
    "    # Extract the 'data' key from the JSON data\n",
    "    data_list1 = json_data['data']\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data_list1)\n",
    "# หาคอลัมน์ที่คุณต้องการสร้าง Donut Chart\n",
    "project_sizes = df.groupby('name_workbook')['size in MB'].sum()\n",
    "\n",
    "# กำหนดสีสำหรับ Donut Chart\n",
    "colors = ['#2A83D4','#74F4EE','#31D0F2']\n",
    "plt.rcParams['font.family'] = 'Tahoma'\n",
    "\n",
    "# สร้าง Donut Chart ที่เล็กลงและไม่มีเงา\n",
    "plt.figure(figsize=(6, 6))\n",
    "\n",
    "# เพิ่มขนาดตัวเลขและรูปแบบตามที่คุณต้องการ\n",
    "autopct_format = '%.1f%%'\n",
    "\n",
    "# เพิ่ม pctdistance เพื่อควบคุมความห่างของค่าเปอร์เซ็นต์จากวงกลม\n",
    "plt.pie(project_sizes, labels=None, autopct=autopct_format, colors=colors, startangle=140, wedgeprops=dict(width=0.3, edgecolor='w'), pctdistance=0.75)\n",
    "\n",
    "# เพิ่มขนาดตัวเลขเปอร์เซ็นต์\n",
    "total_size = project_sizes.sum()\n",
    "center_text = f'พื้นที่ทั้งหมด\\n{total_size:.1f} MB'\n",
    "\n",
    "# เพิ่มขนาดรูโดนัดและขนาดตัวอักษร\n",
    "plt.text(0, 0, center_text, ha='center', va='center', fontsize=14, color='black', fontweight='bold')\n",
    "plt.gcf().gca().add_artist(plt.Circle((0, 0), 0.5, color='white'))\n",
    "\n",
    "# สร้างเลเบลจากข้อมูลในคอลัมน์ 'Project'\n",
    "plt.legend(project_sizes.index, title=\"โปรเจกต์\", bbox_to_anchor=(1, 0.5), loc='center left')\n",
    "\n",
    "# ลบเงา\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.gca().set_frame_on(False)\n",
    "\n",
    "# แสดงกราฟ\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st_query = '''\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    SELECT\n",
    "        bj.created_at AS created_at_local,\n",
    "        bj.id AS ID,\n",
    "        v.name AS Extract,\n",
    "        bj.completed_at AS completed_at_local_nonull,\n",
    "        bj.backgrounder_id AS Backgrounder_Id,\n",
    "        bj.completed_at AS completed_at_local,\n",
    "        bj.job_name AS Job_Name,\n",
    "        aj.notes AS Notes,\n",
    "        bj.priority AS Priority,\n",
    "        bj.processed_on_worker AS Processed_On_Worker,\n",
    "        bj.started_at AS started_at_local,\n",
    "        CASE\n",
    "            WHEN bj.finish_code = 0 THEN 'success'\n",
    "            WHEN bj.finish_code = 1 THEN 'failure'\n",
    "            WHEN bj.finish_code = 2 THEN 'cancelled'\n",
    "            ELSE 'unknown'\n",
    "        END AS status_job,\n",
    "        bj.title AS Title,\n",
    "        bj.job_name AS exetract_task,\n",
    "        s.name AS Site,\n",
    "        bj.finish_code as finish_code,\n",
    "        bj.progress AS progress\n",
    "    FROM\n",
    "        background_jobs bj\n",
    "    LEFT JOIN sites s ON bj.site_id = s.id\n",
    "    LEFT JOIN views v ON s.id = v.site_id\n",
    "    LEFT JOIN async_jobs aj ON s.id = aj.site_id\n",
    "    WHERE \n",
    "        Job_Name = 'Refresh Extracts' AND\n",
    "        EXTRACT(MONTH FROM bj.created_at) = 11 AND \n",
    "        EXTRACT(YEAR FROM bj.created_at) = 2023\n",
    "\n",
    "\n",
    "\n",
    "'''\n",
    "df = pd.read_sql_query(st_query, pg_conn)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "# Assuming df is your DataFrame containing the necessary columns\n",
    "\n",
    "# Convert the 'created_at_local' column to a datetime type\n",
    "df['created_at_local'] = pd.to_datetime(df['created_at_local'])\n",
    "\n",
    "# Filter the DataFrame to include \"Error\" and \"Success\" status\n",
    "error_df = df[df['status_job'] == 'failure']  # Assuming 'failure' corresponds to 'Error'\n",
    "success_df = df[df['status_job'] == 'success']  # Assuming 'success' corresponds to 'Success'\n",
    "\n",
    "# Create the scatter plot for \"Error\" status\n",
    "plt.figure(figsize=(12, 6))\n",
    "error_color = 'red'  # Color for \"Error\" data points\n",
    "plt.scatter(error_df['created_at_local'], error_df['title'], c=error_color, label='มีการทำงานซ้ำ', alpha=0.5)\n",
    "\n",
    "# Create the scatter plot for \"Success\" status\n",
    "success_color = '#7ED957'  # Color for \"Success\" data points\n",
    "plt.scatter(success_df['created_at_local'], success_df['title'], c=success_color, label='สำเร็จ', alpha=0.5)\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('วันที่')\n",
    "plt.ylabel('หน้า dashboard')\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.rcParams['font.family'] = 'Tahoma'\n",
    "\n",
    "# Set the x-axis format to show ticks at 12-hour intervals\n",
    "plt.gca().xaxis.set_major_locator(mdates.DayLocator())  # Adjusted to show ticks at daily intervals\n",
    "plt.gca().xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H:%M:%S'))\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "# Define the custom legend using Line2D\n",
    "custom_legend = [\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#FF0000', markersize=10, label='มีการทำงานซ้ำ'),\n",
    "    Line2D([0], [0], marker='o', color='w', markerfacecolor='#7ED957', markersize=10, label='สำเร็จ')\n",
    "]\n",
    "\n",
    "# Place the legend outside the plot\n",
    "plt.legend(handles=custom_legend, bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()  # Adjust layout to prevent clipping of the legend\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Created At'] = pd.to_datetime(df['created_at_local'])\n",
    "\n",
    "# Extracting the date with timestamp from the 'Created At' column\n",
    "df['Date'] = df['Created At'].dt.floor('D')\n",
    "\n",
    "# Creating the 'Success' and 'Error' columns based on 'Status of Job'\n",
    "df['Success'] = df['status_job'].apply(lambda x: 1 if x == 'success' else 0)\n",
    "df['Error'] = df['status_job'].apply(lambda x: 1 if x == 'error' else 0)\n",
    "\n",
    "# Grouping by 'Date' and aggregating the counts\n",
    "df2 = df.groupby('Date').agg({\n",
    "    'Created At': 'first',  # Assuming you want to keep the first timestamp of the day\n",
    "    'Success': 'sum',\n",
    "    'Error': 'sum'\n",
    "}).reset_index()\n",
    "df2\n",
    "# Renaming the columns as per your request\n",
    "df2.rename(columns={'Created At': 'Created At per day'}, inplace=True)\n",
    "\n",
    "# Convert the 'Date' column to datetime type\n",
    "df2['Date'] = pd.to_datetime(df2['Date'])\n",
    "\n",
    "# Converting the 'Date' column to Thai date format with Buddhist Era year\n",
    "df2['Date'] = df2['Date'].apply(lambda x: f\"{x.day}-{x.month}-{x.year + 543}\")\n",
    "\n",
    "# Drop the 'Created At per day' column\n",
    "df2 = df2.drop(columns=['Created At per day'])\n",
    "\n",
    "df2.rename(columns={'Date': 'วันที่'}, inplace=True)\n",
    "df =df2\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extracts_bar (╯ ͡❛ ͜ʖ ͡❛)╯┻━┻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# อ่านข้อมูลจากไฟล์ CSV\n",
    "# json_file_path = r'C:\\work_on_maholan\\mhl-de-ma-report\\json_file\\Extracts_bar_m11.json'\n",
    "\n",
    "# Read JSON file into DataFrame\n",
    "# df = pd.read_json(json_file_path)\n",
    "# df.fillna(0, inplace=True)\n",
    "\n",
    "# แทนที่ค่า Error เป็น 0\n",
    "df['Error'] = df['Error'].replace('0', 0)\n",
    "\n",
    "# สร้างกราฟ\n",
    "plt.figure(figsize=(16, 8))  # ปรับขนาดกราฟตามที่คุณต้องการ\n",
    "\n",
    "# เพิ่ม grid\n",
    "# plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# สร้างกราฟแท่งสแต็คบาร์\n",
    "width = 0.5\n",
    "x = range(len(df))\n",
    "success_bars = plt.bar(x, df['Success'], width, label='สำเร็จ', color='g')\n",
    "error_bars = plt.bar(x, df['Error'], width, label='ผิดพลาด', hatch='', color='red', bottom=df['Success'])\n",
    "\n",
    "# ปรับแต่งกราฟ\n",
    "plt.xlabel('วันที่')\n",
    "plt.ylabel('จำนวน')\n",
    "plt.rcParams['font.family'] = 'Tahoma'\n",
    "plt.xticks(x, df['วันที่'], rotation='vertical')  # ปรับแต่งแกน x ให้เป็นแนวตั้ง\n",
    "plt.legend()\n",
    "\n",
    "# ระยะห่างด้านบนของกราฟ\n",
    "top_padding = 1  # เพิ่มระยะห่างด้านบนไปอีก 3 นิ้ว\n",
    "\n",
    "# แสดงค่า Success ภายในแต่ละแท่ง\n",
    "# def add_labels(bars, top_padding=0):\n",
    "#     for bar in bars:\n",
    "#         height = bar.get_height()\n",
    "#         plt.annotate(f'{int(height)}', (bar.get_x() + bar.get_width() / 2, height - top_padding), ha='center', va='bottom', fontsize=17)\n",
    "\n",
    "# # เรียกใช้งานฟังก์ชันเพื่อแสดงค่า Success\n",
    "# add_labels(success_bars, top_padding=top_padding)\n",
    "\n",
    "# เพิ่มระยะห่างด้านบนสำหรับค่าผลรวม\n",
    "top_sum = 1\n",
    "# แสดงค่าผลรวมของ Success และ Error ด้านบนกราฟ\n",
    "for i, (success, error) in enumerate(zip(df['Success'], df['Error'])):\n",
    "    if pd.notna(success):  # ตรวจสอบว่าค่า Success ไม่ใช่ NaN\n",
    "        total = success + error\n",
    "        if pd.notna(total):  # ตรวจสอบว่าค่าผลรวมไม่ใช่ NaN\n",
    "            # ใช้ int() หรือ str() เพื่อตัดทศนิยม .0\n",
    "            plt.text(i, total + top_sum, str(int(total)), ha='center', va='bottom', fontweight='bold', fontsize=18)\n",
    "\n",
    "# แสดงกราฟ\n",
    "plt.tight_layout()  # ปรับระยะระหว่างกราฟ\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# อ่านข้อมูลจากไฟล์ CSV\n",
    "\n",
    "\n",
    "# แทนที่ค่า Error เป็น 0\n",
    "df['Error'] = df['Error'].replace('0', 0)\n",
    "\n",
    "# สร้างกราฟ\n",
    "plt.figure(figsize=(16, 8))  # ปรับขนาดกราฟตามที่คุณต้องการ\n",
    "\n",
    "# เพิ่ม grid\n",
    "# plt.grid(True, linestyle='--', alpha=0.6)\n",
    "\n",
    "# สร้างกราฟแท่งสแต็คบาร์\n",
    "width = 0.5\n",
    "x = range(len(df))\n",
    "success_bars = plt.bar(x, df['Success'], width, label='สำเร็จ', color='g', bottom=df['Error'])\n",
    "error_bars = plt.bar(x, df['Error'], width, label='ผิดพลาด', hatch='', color='red')\n",
    "\n",
    "# ปรับแต่งกราฟ\n",
    "plt.xlabel('วันที่')\n",
    "plt.ylabel('จำนวน')\n",
    "plt.rcParams['font.family'] = 'Tahoma'\n",
    "plt.xticks(x, df['วันที่'], rotation='vertical')  # ปรับแต่งแกน x ให้เป็นแนวตั้ง\n",
    "plt.legend()\n",
    "\n",
    "# ระยะห่างด้านบนของกราฟ\n",
    "top_padding = 1  # เพิ่มระยะห่างด้านบนไปอีก 3 นิ้ว\n",
    "\n",
    "# แสดงค่า Success ภายในแต่ละแท่ง\n",
    "def add_labels(bars, top_padding=0):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{int(height)}', (bar.get_x() + bar.get_width() / 2, height - top_padding), ha='center', va='top', fontsize=17)\n",
    "\n",
    "def add_labels(bars, top_padding=0):\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        plt.annotate(f'{int(height)}', (bar.get_x() + bar.get_width() / 2, height - top_padding), ha='center', va='bottom', fontsize=17)\n",
    "\n",
    "# เรียกใช้งานฟังก์ชันเพื่อแสดงค่า Success\n",
    "add_labels(success_bars, top_padding=top_padding)\n",
    "add_labels(error_bars, top_padding=top_padding)\n",
    "\n",
    "# เพิ่มระยะห่างด้านบนสำหรับค่าผลรวม\n",
    "top_sum = 0\n",
    "# แสดงค่าผลรวมของ Success และ Error ด้านบนกราฟ\n",
    "for i, (success, error) in enumerate(zip(df['Success'], df['Error'])):\n",
    "    if pd.notna(success):  # ตรวจสอบว่าค่า Success ไม่ใช่ NaN\n",
    "        total = success + error\n",
    "        if pd.notna(total):  # ตรวจสอบว่าค่าผลรวมไม่ใช่ NaN\n",
    "            # ใช้ int() หรือ str() เพื่อตัดทศนิยม .0\n",
    "            plt.text(i, total + top_sum, str(int(total)), ha='center', va='bottom', fontweight='bold', fontsize=18)\n",
    "\n",
    "# แสดงกราฟ\n",
    "plt.tight_layout()  # ปรับระยะระหว่างกราฟ\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf_query = '''\n",
    "\n",
    " select * from historical_disk_usage hdu;\n",
    "\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Size by Project_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Define your PostgreSQL connection parameters\n",
    "\n",
    "# Create a connection to the database using the connection parameters\n",
    "conn = psycopg2.connect(**tableau_db_params)\n",
    "\n",
    "# Create a cursor to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute your SQL query\n",
    "cur.execute(\"\"\"\n",
    "WITH all_days AS (\n",
    "  SELECT generate_series(\n",
    "    DATE '2022-10-01',\n",
    "    DATE '2022-10-31',\n",
    "    INTERVAL '1 day'\n",
    "  )::DATE AS day\n",
    ")\n",
    "SELECT all_days.day,\n",
    "       COALESCE(COUNT(data_connections.created_at), 0) AS count,\n",
    "       EXTRACT(DAY FROM all_days.day) AS day_of_month\n",
    "FROM all_days\n",
    "LEFT JOIN data_connections ON DATE_TRUNC('day', all_days.day) = DATE_TRUNC('day', data_connections.created_at)\n",
    "GROUP BY all_days.day\n",
    "ORDER BY all_days.day;\n",
    "\"\"\")\n",
    "\n",
    "# Fetch the results\n",
    "results = cur.fetchall()\n",
    "\n",
    "# Close the cursor and the database connection\n",
    "cur.close()\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Separate the day of the month and counts from the results\n",
    "day_of_month = [row[2] for row in results]\n",
    "count = [int(row[1]) for row in results]  # Convert to integer to remove .0\n",
    "\n",
    "# Set the figure size and style\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "# Create a bar graph with a custom background color\n",
    "plt.bar(day_of_month, count, color='skyblue')  # Set color to sky blue for the bars\n",
    "plt.xlabel(\"Day of the Month\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Traffic to data of the Month\")\n",
    "\n",
    "# Set x-axis to display all days of the month\n",
    "plt.xticks(range(1, 32))\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)  # Add dashed horizontal grid lines\n",
    "\n",
    "# Add labels to the bars with adjusted position (c)\n",
    "for i, c in enumerate(count):\n",
    "    plt.text(day_of_month[i], c, str(c), ha='center', va='bottom')\n",
    "\n",
    "# Customize the background color to white\n",
    "plt.gcf().set_facecolor('white')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psycopg2\n",
    "\n",
    "# Define your PostgreSQL connection parameters\n",
    "\n",
    "# Create a connection to the database using the connection parameters\n",
    "conn = psycopg2.connect(**tableau_db_params)\n",
    "\n",
    "# Create a cursor to interact with the database\n",
    "cur = conn.cursor()\n",
    "\n",
    "# Execute your SQL query\n",
    "cur.execute(\"\"\"\n",
    "WITH view_names AS (\n",
    "    SELECT id, name\n",
    "    FROM views\n",
    ")\n",
    "SELECT\n",
    "    vn.view_id,\n",
    "    vn.total_query_batch_time_in_seconds,\n",
    "    vn.name,\n",
    "    vn.count\n",
    "FROM (\n",
    "    SELECT\n",
    "        mvs.view_id,\n",
    "        mvs.total_query_batch_time_in_seconds,\n",
    "        vn.name,\n",
    "        COUNT(*) OVER (PARTITION BY vn.name) AS count\n",
    "    FROM materialized_views_sheet_performance mvs\n",
    "    INNER JOIN view_names vn ON mvs.view_id = vn.id\n",
    "    WHERE mvs.day_timestamp >= '2023-01-01' AND mvs.day_timestamp <= '2023-10-30'\n",
    ") vn\n",
    "WHERE vn.count <> 1;\n",
    "\"\"\")\n",
    "\n",
    "# Fetch the results\n",
    "results = cur.fetchall()\n",
    "\n",
    "# Close the cursor and the database connection\n",
    "cur.close()\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = results\n",
    "\n",
    "data.sort(key=lambda x: x[2])  # Sort the data based on the name\n",
    "\n",
    "# Use defaultdict to aggregate values and count occurrences of each name\n",
    "name_to_values = defaultdict(list)\n",
    "name_to_counts = defaultdict(int)\n",
    "\n",
    "for _, value, name, _ in data:\n",
    "    name_to_values[name].append(value)\n",
    "    name_to_counts[name] += 1\n",
    "\n",
    "# Calculate the average value for each name\n",
    "name_to_avg = {name: sum(values) / name_to_counts[name] for name, values in name_to_values.items()}\n",
    "\n",
    "# Convert the data for the graph and sort it by average value (ascending order)\n",
    "sorted_names = list(name_to_avg.keys())\n",
    "sorted_values = list(name_to_avg.values())\n",
    "sorted_names, sorted_values = zip(*sorted(zip(sorted_names, sorted_values), key=lambda x: x[1]))\n",
    "\n",
    "# Define color thresholds and their meanings in the get_color function\n",
    "def get_color(value):\n",
    "    if value < 1:\n",
    "        return 'limegreen'\n",
    "    elif 1 <= value < 5:\n",
    "        return 'gold'\n",
    "    else:\n",
    "        return 'tomato'\n",
    "\n",
    "# Get colors for each bar based on the values\n",
    "bar_colors = [get_color(value) for value in sorted_values]\n",
    "\n",
    "# Create a larger horizontal bar graph\n",
    "plt.figure(figsize=(14, 10))  # Adjust the figure size as needed\n",
    "\n",
    "# Set the x-axis limits to start from 0\n",
    "plt.xlim(0, max(sorted_values) + 1.0)\n",
    "\n",
    "# Set the x-axis to display values\n",
    "bars = plt.barh(sorted_names, sorted_values, color=bar_colors)\n",
    "\n",
    "# Set axis labels\n",
    "plt.ylabel('ชื่อ Work Book')\n",
    "plt.xlabel('เวลาค่าเฉลี่ยของเเต่ละหน้า(มีหน่วยเป็นวินาที)')\n",
    "\n",
    "# Create a legend with color explanations\n",
    "legend_labels = {'limegreen': 'Normal Status (การโหลดปกติ)', 'gold': 'Warning Status (การโหลดล่าช้า)', 'tomato': 'Critical Status (การโหลดมีปัญหา) '}\n",
    "handles = [plt.Rectangle((0, 0), 1, 1, color=color) for color in legend_labels.keys()]\n",
    "plt.legend(handles, legend_labels.values(), loc='upper right')\n",
    "\n",
    "# Add data labels to the bars without overlapping\n",
    "for value, name in zip(sorted_values, sorted_names):\n",
    "    plt.text(value, name, f'{value:.2f}', ha='left', va='center')\n",
    "\n",
    "# ax.invert_yaxis()\n",
    "\n",
    "# ax.set_title('Load time of top 10 most view dashboards')\n",
    "ax.grid()\n",
    "plt.rcParams['font.family'] = 'Tahoma'\n",
    "\n",
    "# ax.get_axisbelow()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Most view dashboard (╯ ͡❛ ͜ʖ ͡❛)╯┻━┻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "\n",
    "# Specify the URL to fetch JSON data\n",
    "url = os.getenv('REPORT_SERVICE')+f\"tableau/Top5_View_Dashboard?month={month}&year={year}\" #\"http://localhost:1234/report-service/api/v1/tableau/Top5_View_Dashboard?month=12&year=2023\"\n",
    "\n",
    "# Add Bearer token to the request headers\n",
    "headers = {\n",
    "    'Authorization': 'Bearer POPPOPNIX',  # Replace '1234' with your actual token\n",
    "}\n",
    "\n",
    "# Fetch JSON data from the URL with headers\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful (status code 200)\n",
    "if response.status_code == 200:\n",
    "    json_data = response.json()\n",
    "    \n",
    "    # Extract the 'data' key from the JSON data\n",
    "    data_list1 = json_data.get('total_runs', {}).get('data', [])\n",
    "\n",
    "    # Create a DataFrame from the list of dictionaries\n",
    "    df = pd.DataFrame(data_list1)\n",
    "# สร้างกราฟแนวนอน\n",
    "# สร้างกราฟแนวนอน\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(df['title'], df['view_count'], color='skyblue')\n",
    "plt.xlabel('จำนวนที่เข้าดู')\n",
    "plt.ylabel('หน้า Dashboard')\n",
    "plt.gca().invert_yaxis()  # เรียงลำดับจากมากไปน้อย\n",
    "\n",
    "# ปรับแต่งคำอธิบายด้านข้างของกราฟ\n",
    "for i, count in enumerate(df['view_count']):\n",
    "    plt.text(count, i, f' {count}', va='center')\n",
    "# plt.savefig('top_5_views.png')\n",
    "ax.invert_yaxis()\n",
    "\n",
    "# ax.set_title('Load time of top 10 most view dashboards')\n",
    "ax.grid()\n",
    "# ax.get_axisbelow()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
